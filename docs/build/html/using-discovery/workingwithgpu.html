

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Working with GPUs &mdash; Northeastern University Research Computing 0.0.2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'0.0.2',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Transferring Data" href="transferringdata.html" />
    <link rel="prev" title="Slurm examples" href="slurmexamples.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/NU_logo_small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Welcome</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../welcome/welcome.html">Welcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="../welcome/gettinghelp.html">Getting Help</a></li>
</ul>
<p class="caption"><span class="caption-text">Getting Started with Discovery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get_started/get_access.html">Getting Access</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/recommended_tools.html">Recommended Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/connect.html">Connecting to Discovery</a></li>
</ul>
<p class="caption"><span class="caption-text">Hardware on Discovery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../hardware/hardware_overview.html">Hardware overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware/partitions.html">Partitions</a></li>
</ul>
<p class="caption"><span class="caption-text">Software on Discovery</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../software/modules.html">Using Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/software.html">Installing Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software/matlab.html">Working with MATLAB Parallel Computing Toolbox</a></li>
</ul>
<p class="caption"><span class="caption-text">Using Discovery</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="usingslurm.html">Using Slurm</a></li>
<li class="toctree-l1"><a class="reference internal" href="slurmexamples.html">Slurm examples</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Working with GPUs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#requesting-gpus-with-srun-or-sbatch">Requesting GPUs with <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">sbatch</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#specifying-a-gpu-type">Specifying a GPU type</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#using-cuda">Using CUDA</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-gpus-with-pytorch">Using GPUs with PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-tensorflow">Using TensorFlow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="transferringdata.html">Transferring Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="globus.html">Using Globus</a></li>
</ul>
<p class="caption"><span class="caption-text">Understanding storage options</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../storage/discovery_storage.html">Storage Accessible on  Discovery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../storage/general_storage.html">General Data Storage Options</a></li>
</ul>
<p class="caption"><span class="caption-text">Using Open OnDemand (OOD)</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../using-ood/introduction.html">Introduction to Open OnDemand (OOD)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../using-ood/fileexplore.html">Using OOD’s File Explorer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../using-ood/interactiveapps.html">Using OOD’s Interactive Apps</a></li>
</ul>
<p class="caption"><span class="caption-text">Using Discovery in your classroom</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../classroom/class_use.html">Using Discovery with your class FAQ</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Northeastern University Research Computing</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Working with GPUs</li>
    
    

  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="working-with-gpus">
<h1>Working with GPUs<a class="headerlink" href="#working-with-gpus" title="Permalink to this headline">¶</a></h1>
<p>The Discovery cluster has a number of Graphics Processing Units (GPUs) available, as detailed in the table below.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">GPU Type</th>
<th class="head">Number of nodes/GPUs</th>
<th class="head">CPU Type</th>
<th class="head">RAM per node</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>k20m</td>
<td>23 nodes with 1 GPU each</td>
<td>E5-2650&#64;2.00GHz</td>
<td>128GB</td>
</tr>
<tr class="row-odd"><td>k40m</td>
<td>16 nodes with 1 GPU each</td>
<td>E5-2690v3&#64;2.60GHz</td>
<td>128GB</td>
</tr>
<tr class="row-even"><td>k80</td>
<td>8 nodes with 8 GPUs each</td>
<td>E5-2680v4&#64;2.40GHz</td>
<td>512GB</td>
</tr>
<tr class="row-odd"><td>p100</td>
<td>12 nodes with 4 GPUs each</td>
<td>E5-2680v4&#64;2.40GHz</td>
<td>512GB</td>
</tr>
<tr class="row-even"><td>v100</td>
<td>4 nodes with 2 GPUs each</td>
<td>AMD EPYC 7351&#64;2.60GHz</td>
<td>480GB</td>
</tr>
<tr class="row-odd"><td>v100-sxm2</td>
<td>24 nodes with 4 GPUs each</td>
<td>Intel Gold 6132&#64;2.60Ghz</td>
<td>187GB</td>
</tr>
</tbody>
</table>
<p>These GPUs are available within two partitions, named <code class="docutils literal notranslate"><span class="pre">gpu</span></code> and <code class="docutils literal notranslate"><span class="pre">multigpu</span></code>. Note that partitions on Discovery are not physical partitions, they  are virtual partitions. The differences between the two partitions are the number of GPUs that you can request per job, as well as the time
limit on each job. Both partitions give you access to all of the above GPU types. See the table below for the differences between the two partitions.</p>
<table border="1" class="colwidths-given docutils">
<colgroup>
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Name</th>
<th class="head">Requires Approval?</th>
<th class="head">Time limit (Default/Max)</th>
<th class="head">Running Jobs</th>
<th class="head">Submitted Jobs</th>
<th class="head">Core Limit</th>
<th class="head">RAM Limit</th>
<th class="head">GPU per job Limit</th>
<th class="head">GPU per user Limit</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>gpu</td>
<td>No</td>
<td>4 hours/8 Hours</td>
<td>25/250</td>
<td>50/100</td>
<td>N/A</td>
<td>N/A</td>
<td>1</td>
<td>8</td>
</tr>
<tr class="row-odd"><td>multigpu</td>
<td><strong>Yes</strong></td>
<td>4 hours/24 Hours</td>
<td>25/100</td>
<td>50/100</td>
<td>N/A</td>
<td>N/A</td>
<td>8</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>Anyone with an account on Discovery can use the <code class="docutils literal notranslate"><span class="pre">gpu</span></code> partition. Using <code class="docutils literal notranslate"><span class="pre">`multigpu</span></code> requires an application process, which includes documenting
the need for using <code class="docutils literal notranslate"><span class="pre">multigpu</span></code>. You can find the application for <code class="docutils literal notranslate"><span class="pre">multigpu</span></code> and how to submit it in the Policies section on the
<a class="reference external" href="https://rc.northeastern.edu/files/2020/02/access_request_multigpu.docx">RC website</a>.</p>
<div class="section" id="requesting-gpus-with-srun-or-sbatch">
<h2>Requesting GPUs with <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">sbatch</span></code><a class="headerlink" href="#requesting-gpus-with-srun-or-sbatch" title="Permalink to this headline">¶</a></h2>
<p>Use <code class="docutils literal notranslate"><span class="pre">srun</span></code> for interactive mode and <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> for batch mode.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">srun</span></code> example below is requesting 1 node and 1 GPU with 1GB of memory in the <code class="docutils literal notranslate"><span class="pre">gpu</span></code> partition. Note that on the <code class="docutils literal notranslate"><span class="pre">gpu</span></code> partition, you cannot request more than 1 GPU (<code class="docutils literal notranslate"><span class="pre">--gres=gpu:1</span></code>)
or your request will fail.</p>
<p><code class="docutils literal notranslate"><span class="pre">srun</span> <span class="pre">--partition</span> <span class="pre">gpu</span> <span class="pre">--nodes</span> <span class="pre">1</span> <span class="pre">--pty</span> <span class="pre">--export=All</span> <span class="pre">--gres=gpu:1</span> <span class="pre">--mem=1Gb</span> <span class="pre">--time=00:30:00</span> <span class="pre">/bin/bash</span></code></p>
<p>The <code class="docutils literal notranslate"><span class="pre">sbatch</span></code> example below is the similar to the <code class="docutils literal notranslate"><span class="pre">srun</span></code> example above, except for giving the job a name and directing the output to a file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#SBATCH --nodes=1</span>
<span class="c1">#SBATCH --time=0:30:00</span>
<span class="c1">#SBATCH --job-name=gpu_run</span>
<span class="c1">#SBATCH --mem=1Gb</span>
<span class="c1">#SBATCH --gres=gpu:1</span>
<span class="c1">#SBATCH --output=exec.%j.out</span>
<span class="o">&lt;</span><span class="n">your</span> <span class="n">code</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="section" id="specifying-a-gpu-type">
<h3>Specifying a GPU type<a class="headerlink" href="#specifying-a-gpu-type" title="Permalink to this headline">¶</a></h3>
<p>You can add a specific type of GPU to the <code class="docutils literal notranslate"><span class="pre">--gres=</span></code> option (with either <code class="docutils literal notranslate"><span class="pre">srun</span></code> or <code class="docutils literal notranslate"><span class="pre">sbatch</span></code>). For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">gres</span><span class="o">=</span><span class="n">gpu</span><span class="p">:</span><span class="n">k40m</span><span class="p">:</span><span class="mi">1</span>
</pre></div>
</div>
<p>Note that specifying one type of GPU could result in a longer wait time for that specific resource.</p>
</div>
</div>
<div class="section" id="using-cuda">
<h2>Using CUDA<a class="headerlink" href="#using-cuda" title="Permalink to this headline">¶</a></h2>
<p>Currently, there are four versions of CUDA on Discovery:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cuda</span><span class="o">/</span><span class="mf">9.0</span>
<span class="n">cuda</span><span class="o">/</span><span class="mf">9.2</span>
<span class="n">cuda</span><span class="o">/</span><span class="mf">10.0</span>
<span class="n">cuda</span><span class="o">/</span><span class="mf">10.2</span>
</pre></div>
</div>
<p>You can always use the <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">avail</span></code> command to check for the latest software versions on Discovery as well.</p>
<p>To add CUDA to your path use <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span></code>. For example, type <code class="docutils literal notranslate"><span class="pre">module</span> <span class="pre">load</span> <span class="pre">cuda/10.0</span></code> to load version 10 to your path.</p>
</div>
<div class="section" id="using-gpus-with-pytorch">
<h2>Using GPUs with PyTorch<a class="headerlink" href="#using-gpus-with-pytorch" title="Permalink to this headline">¶</a></h2>
<p>You should use PyTorch with a conda virtual environment if you need to run the environment on the Nvidia GPUs on Discovery.</p>
<p>The following is an example of using a conda virtual environment with PyTorch. Make sure that you are on a GPU node before loading the environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">cuda</span><span class="o">/</span><span class="mf">10.2</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">anaconda3</span><span class="o">/</span><span class="mf">3.7</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">--</span><span class="n">name</span> <span class="n">pytorch_env</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.7</span> <span class="n">anaconda</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">pytorch_env</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">pytorch</span> <span class="n">torchvision</span> <span class="n">cudatoolkit</span><span class="o">=</span><span class="mf">10.2</span> <span class="o">-</span><span class="n">c</span> <span class="n">pytorch</span>
<span class="n">python</span> <span class="o">-</span><span class="n">c</span><span class="s1">&#39;import torch; print(torch.cuda.is_available())&#39;</span>
</pre></div>
</div>
</div>
<div class="section" id="using-tensorflow">
<h2>Using TensorFlow<a class="headerlink" href="#using-tensorflow" title="Permalink to this headline">¶</a></h2>
<p>We recommend that you use CUDA 10.2 with the latest version of TensorFlow.
You can find the compatibility of CUDA and TensorFlow versions at the following website <a class="reference external" href="https://www.tensorflow.org/install/source#gpu">https://www.tensorflow.org/install/source#gpu</a>.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">module</span> <span class="n">load</span> <span class="n">anaconda3</span><span class="o">/</span><span class="mf">3.7</span>
<span class="n">module</span> <span class="n">load</span> <span class="n">cuda</span><span class="o">/</span><span class="mf">10.2</span>
<span class="n">conda</span> <span class="n">create</span> <span class="o">--</span><span class="n">name</span> <span class="n">TF_env</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.7</span> <span class="n">anaconda</span> <span class="c1">#where TF_env is the name of the conda environment</span>
<span class="n">conda</span>  <span class="n">activate</span> <span class="n">TF_env</span>
<span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">anaconda</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">gpu</span>
</pre></div>
</div>
<p>If you want to test your environment, first make sure you are on GPU node, then type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s1">&#39;import tensorflow as tf;  print(tf.test.is_built_with_cuda())&#39;</span>
</pre></div>
</div>
<p>You should see the result <code class="docutils literal notranslate"><span class="pre">True</span></code> if successful.</p>
<p>To get the name of the GPU, type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">c</span> <span class="s1">&#39;import tensorflow as tf;  print(tf.test.gpu_device_name())&#39;</span>
</pre></div>
</div>
<p>For example, you should see output like the line below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">physical</span> <span class="n">GPU</span> <span class="p">(</span><span class="n">device</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Tesla</span> <span class="n">K40m</span><span class="p">,</span> <span class="n">pci</span> <span class="n">bus</span> <span class="nb">id</span><span class="p">:</span> <span class="mi">0000</span><span class="p">:</span><span class="mi">0</span><span class="n">b</span><span class="p">:</span><span class="mf">00.0</span><span class="p">,</span> <span class="n">compute</span> <span class="n">capability</span><span class="p">:</span> <span class="mf">3.5</span><span class="p">)</span> <span class="o">/</span><span class="n">device</span><span class="p">:</span><span class="n">GPU</span><span class="p">:</span><span class="mi">0</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="transferringdata.html" class="btn btn-neutral float-right" title="Transferring Data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="slurmexamples.html" class="btn btn-neutral float-left" title="Slurm examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-2020, Northeastern University Research Computing

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>